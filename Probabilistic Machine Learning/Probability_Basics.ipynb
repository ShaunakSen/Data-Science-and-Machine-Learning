{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Probability for Machine Learning\n\n> Notes based on blog by Jason Brownlee: https://machinelearningmastery.com/bayes-theorem-for-machine-learning/\n\n---",
   "metadata": {
    "tags": [],
    "cell_id": "00000-5882e3fc-a9d8-4d68-8ff0-9436b3659b94",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Basic concepts\n<img src=\"https://i.imgur.com/l3GDwZR.jpeg\" width=\"600\" height=\"700\"/>\n<img src=\"https://i.imgur.com/eX5ELeX.jpeg\" width=\"600\" height=\"700\"/>\n",
   "metadata": {
    "tags": [],
    "cell_id": "00001-7b424c00-f42f-4d9b-8506-461e072756ac",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Worked Example for Calculating Bayes Theorem\n\n\nScenario: Consider a human population that may or may not have cancer (Cancer is True or False) and a medical test that returns positive or negative for detecting cancer (Test is Positive or Negative), e.g. like a mammogram for detecting breast cancer.\n\n<img src=\"https://i.imgur.com/MZ7lHIA.jpeg\" width=\"600\" height=\"800\"/>\n<img src=\"https://i.imgur.com/QdgcEA7.jpeg\" width=\"700\" height=\"400\"/>\n",
   "metadata": {
    "tags": [],
    "cell_id": "00002-02cdcf8d-c7d2-4d65-aecf-a8fd8f3af78f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "The calculation suggests that if the patient is informed they have cancer with this test, then there is only 0.33% chance that they have cancer.\n\nThe example also shows that the calculation of the conditional probability requires enough information.\n\nFor example, if we have the values used in Bayes Theorem already, we can use them directly.\n\nThis is rarely the case, and we typically have to calculate the bits we need and plug them in, as we did in this case. In our scenario we were given 3 pieces of information, the the base rate (P(cancer)), the  sensitivity (or true positive rate - P(+ve | cancer)), and the specificity (or true negative rate - P(-ve|not cancer)).\n\n- Sensitivity: 85% of people with cancer will get a positive test result.\n- Base Rate: 0.02% of people have cancer.\n- Specificity: 95% of people without cancer will get a negative test result.\n",
   "metadata": {
    "tags": [],
    "cell_id": "00003-af9fab40-25a7-403f-9e78-98d38ae1d647",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Baye's Theorem in Python",
   "metadata": {
    "tags": [],
    "cell_id": "00004-6aaa1a91-832f-458e-a326-1196961ee942",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-bc144ccf-6908-45b4-8b9a-d62fd28fe36e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8da4f9ad",
    "execution_start": 1624089094010,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "source": "#### A: cancer B: test; need P(A|B)\n\ndef bayes_theorem(p_a, p_b_given_a, p_not_b_given_not_a):\n    \"\"\"\n    Inputs:\n    p_a: base rate\n    p_b_given_a: TPR: sensitivity\n    p_not_b_given_not_a : TNR: specificity\n\n    Returns P(A|B)\n    \"\"\"\n\n    p_not_a = 1 - p_a\n    p_b_given_not_a = 1 - p_not_b_given_not_a\n\n    p_b = p_b_given_a * p_a + p_b_given_not_a*p_not_a\n\n    p_a_given_b = (p_b_given_a * p_a)/p_b\n\n    return p_a_given_b\n\np_a = 0.0002\np_b_given_a = 0.85\np_not_b_given_not_a = 0.95\n\nresult = bayes_theorem(p_a, p_b_given_a, p_not_b_given_not_a)\nprint('P(A|B) = %.3f%%' % (result * 100))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "P(A|B) = 0.339%\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Binary Classifier Terminology\n\n\nIt may be helpful to think about the cancer test example in terms of the common terms from binary (two-class) classification, i.e. where notions of specificity and sensitivity come from.\n\n![](https://i.imgur.com/0nKYJTi.png)\n\nRecall that in a previous section that we calculated the false positive rate given the complement of true negative rate, or FPR = 1.0 – TNR.\n\nSome of these rates have special names, for example:\n\n- Sensitivity = TPR\n- Specificity = TNR\n\nWe can map these rates onto familiar terms from Bayes Theorem (A: cancer B: test):\n\n- P(B|A): True Positive Rate (TPR).\n- P(not B|not A): True Negative Rate (TNR).\n- P(B|not A): False Positive Rate (FPR).\n- P(not B|A): False Negative Rate (FNR).\n\nWe can also map the base rates for the condition (class) and the treatment (prediction) on familiar terms from Bayes Theorem:\n\n- P(A): Probability of a Positive Class (PC).\n- P(not A): Probability of a Negative Class (NC).\n- P(B): Probability of a Positive Prediction (PP).\n- P(not B): Probability of a Negative Prediction (NP).\n\nNow, let’s consider Bayes Theorem using these terms:\n\n```\nP(A|B) = P(B|A) * P(A) / P(B)\n\nP(A|B) = (TPR * PC) / PP\n\nWhere we often cannot calculate P(B), so we use an alternative:\n\nP(B) = P(B|A) * P(A) + P(B|not A) * P(not A)\nP(B) = TPR * PC + FPR * NC\n\n```\nNow, let’s look at our scenario of cancer and a cancer detection test.\n\n- True Positive Rate (TPR): 85%\n- False Positive Rate (FPR): 5% (1-TNR)\n- True Negative Rate (TNR): 95%\n- False Negative Rate (FNR): 15% (1-TPR)\n\nLet’s also review what we know about base rates:\n\n- Positive Class (PC): 0.02%\n- Negative Class (NC): 99.98%\n\n\n```\nP(B) = P(B|A) * P(A) + P(B|not A) * P(not A)\nP(B) = TPR * PC + FPR * NC\nP(B) = 85% * 0.02% + 5% * 99.98%\nP(B) = 5.016%\n\n\nP(A|B) = P(B|A) * P(A) / P(B)\nP(A|B) = TPR * PC / PP\nP(A|B) = 85% * 0.02% / 5.016%\nP(A|B) = 0.339%\n```\n\n#### Conditional probabilities in terms of precision and recall\n\nWhen a search engine returns 30 pages, only 20 of which are relevant, while failing to return 40 additional relevant pages, its precision is 20/30 = 2/3, which tells us how valid the results are, while its recall is 20/60 = 1/3, which tells us how complete the results are.\n\nB : test returned +ve\nA: determines if actually cancer\n\nSo P(A|B) is actually telling us how valid the results are\n\nprecision = TP/(TP+FP) = TPR*PC/PP = P(A|B) as we have seen earlier\n\nrecall = TP/(TP+FN) = TPR*PC/PC = P(B|A) * P(A)/P(A) = P(B|A) -> given cancer is there what is the prob that test returns cancer -> given 30 results are there, how many are returned\n",
   "metadata": {
    "tags": [],
    "cell_id": "00006-7b63b9fb-7bc7-446b-85c7-e43649ebb49b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### How Baye's Theorem fits in MAP and MLE\n\nBayes Theorem is a useful tool in applied machine learning. It provides a way of thinking about the relationship between data and a model.\n\nA machine learning algorithm or model is a specific way of thinking about the structured relationships in the data. In this way, a model can be thought of as a hypothesis about the relationships in the data, such as the relationship between input (X) and output (y). The practice of applied machine learning is the testing and analysis of different hypotheses (models) on a given dataset.\n\nBayes Theorem provides a probabilistic model to describe the relationship between data (D) and a hypothesis (h); for example:\n\nP(h|D) = P(D|h) * P(h) / P(D)\n\nBreaking this down, it says that the probability of a given hypothesis holding or being true given some observed data can be calculated as the probability of observing the data given the hypothesis multiplied by the probability of the hypothesis being true regardless of the data, divided by the probability of observing the data regardless of the hypothesis.\n\nUnder this framework, each piece of the calculation has a specific name; for example:\n\n- P(h|D): Posterior probability of the hypothesis (the thing we want to calculate).\n- P(h): Prior probability of the hypothesis.\n\nIf we have some prior domain knowledge about the hypothesis, this is captured in the prior probability. If we don’t, then all hypotheses may have the same prior probability.\n\nIf the probability of observing the data P(D) increases, then the probability of the hypothesis holding given the data P(h|D) decreases. Conversely, if the probability of the hypothesis P(h) and the probability of observing the data given hypothesis increases, the probability of the hypothesis holding given the data P(h|D) increases.\n\nThe notion of testing different models on a dataset in applied machine learning can be thought of as estimating the probability of each hypothesis (h1, h2, h3, … in H) being true given the observed data.\n\nThe optimization or seeking the hypothesis with the maximum posterior probability in modeling is called maximum a posteriori or MAP for short.\n\nAny such maximally probable hypothesis is called a maximum a posteriori (MAP) hypothesis. We can determine the MAP hypotheses by using Bayes theorem to calculate the posterior probability of each candidate hypothesis.\n\nUnder this framework, the probability of the data (D) is constant as it is used in the assessment of each hypothesis. Therefore, it can be removed from the calculation to give the simplified unnormalized estimate as follows:\n\n`max h in H P(h|D) = P(D|h) * P(h)`\n\nIf we do not have any prior information about the hypothesis being tested, they can be assigned a uniform probability, and this term too will be a constant and can be removed from the calculation to give the following:\n\n`max h in H P(h|D) = P(D|h)` - MAP framework (we want to maximize the posteriori hypothesis amongst all possible hypothesis)\n\n\nThat is, the goal is to locate a hypothesis that best explains the observed data. Fitting models like linear regression for predicting a numerical value, and logistic regression for binary classification can be framed and solved under the MAP probabilistic framework. This provides an alternative to the more common maximum likelihood estimation (MLE) framework.\n\nThere are two probabilistic frameworks that underlie many different machine learning algorithms.\n- Maximum a Posteriori (MAP), a Bayesian method.\n- Maximum Likelihood Estimation (MLE), a frequentist method.\n\nThe objective of both of these frameworks in the context of machine learning is to locate the hypothesis that is most probable given the training dataset.\nSpecifically, they answer the question: What is the most probable hypothesis given the training data?\n\nBoth approaches frame the problem of fitting a model as optimization and involve searching for a distribution and set of parameters for the distribution that best describes the observed data.\n\nGiven the simplification of Bayes Theorem to a proportional quantity, we can use it to estimate the proportional hypothesis and parameters (theta) that explain our dataset (X), stated as:\n\n`P(theta | X) = P(X | theta) * P(theta)`-Maximizing this quantity over a range of theta solves an optimization problem for estimating the central tendency of the posterior probability (e.g. the model of the distribution). As such, this technique is referred to as “maximum a posteriori estimation,” or MAP estimation for short, and sometimes simply “maximum posterior estimation.” - `maximize P(X | theta) * P(theta)`\n\nNow that we are familiar with the MAP framework, we can take a closer look at the related concept of the Bayes optimal classifier.\n\n#### Bayes Optimal Classifier\n\nThe Bayes optimal classifier is a probabilistic model that makes the most probable prediction for a new example, given the training dataset. This model is also referred to as the Bayes optimal learner, the Bayes classifier, Bayes optimal decision boundary, or the Bayes optimal discriminant function. Specifically, the Bayes optimal classifier answers the question - What is the most probable classification of the new instance given the training data?\n\nMAP : What is the most probable hypothesis given the training data? | Bayes Optimal Classifier: What is the most probable classification of the new instance given the training data. This is different from the MAP framework that seeks the most probable hypothesis (model). Instead, we are interested in making a specific prediction.\n\nThe equation below demonstrates how to calculate the conditional probability for a new instance (vi) given the training data (D), given a space of hypotheses (H).\n\n`P(vj | D) = sum {h in H} P(vj | hi) * P(hi | D)`\n\nWhere vj is a new instance to be classified, H is the set of hypotheses for classifying the instance, hi is a given hypothesis, P(vj | hi) is the posterior probability for vi given hypothesis hi, and P(hi | D) is the posterior probability of the hypothesis hi given the data D.\n\nFor example consider we have 3 hypothesis : h1,h2,h3, and we get an instance v_i\n\n`P(vi|D) = P(vi|h1)*P(h1|D) + P(vi|h2)*P(h2|D) + P(vi|h2)*P(h2|D)`\n\nSelecting the outcome with the maximum probability is an example of a Bayes optimal classification.\n\nvi might be obseving a class label - `P(vi|D) gives a prob for that class - Selecting the outcome with the maximum probability is an example of a Bayes optimal classification.\n\n> Any model that classifies examples using this equation is a Bayes optimal classifier and no other model can outperform this technique, on average.\nIn theory we would always like to predict qualitative responses using the Bayes classifier. But for real data, we do not know the conditional distribution of Y given X, and so computing the Bayes classifier is impossible. Therefore, the Bayes classifier serves as an unattainable gold standard against which to compare other methods.\n\n\nWe have to let that sink in.\n\nIt is a big deal.\n\nIt means that any other algorithm that operates on the same data, the same set of hypotheses, and same prior probabilities cannot outperform this approach, on average. Hence the name “optimal classifier.”\n\nAlthough the classifier makes optimal predictions, it is not perfect given the uncertainty in the training data and incomplete coverage of the problem domain and hypothesis space. As such, the model will make errors. These errors are often referred to as Bayes errors.\n\n__Bayes Error__: The minimum possible error that can be made when making predictions.\n\nBecause of the computational cost of this optimal strategy, we instead can work with direct simplifications of the approach.\n\nNaive Bayes: Assume that variables in the input data are conditionally independent.\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00007-03d272ec-1287-4212-857a-4df2062852f3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Bayes Theorem for Classification\n\nClassification is a predictive modeling problem that involves assigning a label to a given input data sample. The problem of classification predictive modeling can be framed as calculating the conditional probability of a class label given a data sample, for example:\n\n- P(class|data) = (P(data|class) * P(class)) / P(data)\n\nWhere P(class|data) is the probability of class given the provided data. This calculation can be performed for each class in the problem and the class that is assigned the largest probability can be selected and assigned to the input data.\n\n__In practice, it is very challenging to calculate full Bayes Theorem for classification.__\n\nThe priors for the class and the data are easy to estimate from a training dataset, if the dataset is suitability representative of the broader problem.\n\nThe conditional probability of the observation based on the class P(data|class) is not feasible unless the number of examples is extraordinarily large, e.g. large enough to effectively estimate the probability distribution for all different possible combinations of values. This is almost never the case, we will not have sufficient coverage of the domain.\n\nAs such, the direct application of Bayes Theorem also becomes intractable, especially as the number of variables or features (n) increases.\n\n\n\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00008-380d3a93-e67a-4b24-a7ee-47b8a44de860",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Naive Bayes Classifier\n\nThe solution to using Bayes Theorem for a conditional probability classification model is to simplify the calculation.\n\nThe Bayes Theorem assumes that each input variable is dependent upon all other variables. This is a cause of complexity in the calculation. We can remove this assumption and consider each input variable as being independent from each other.\n\nThis changes the model from a dependent conditional probability model to an independent conditional probability model and dramatically simplifies the calculation.\n\nThis means that we calculate P(data|class) for each input variable separately and multiple the results together, for example:\n\n`P(class | X1, X2, …, Xn) = P(X1|class) * P(X2|class) * … * P(Xn|class) * P(class) / P(data)`\n\nWe can also drop the probability of observing the data as it is a constant for all calculations, for example:\n\n`P(class | X1, X2, …, Xn) = P(X1|class) * P(X2|class) * … * P(Xn|class) * P(class)`\n\nThis simplification of Bayes Theorem is common and widely used for classification predictive modeling problems and is generally referred to as Naive Bayes.\n\nThe word “naive” is French and typically has a diaeresis (umlaut) over the “i”, which is commonly left out for simplicity, and “Bayes” is capitalized as it is named for Reverend Thomas Bayes.\n\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00009-0fc3a1e3-8ba4-4963-84ce-52bb45885a4e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e3bd92dc-1f37-46e3-a6da-869792ce3a08' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "34331d46-6792-4c4a-ae03-8a74115fb2c9",
  "deepnote_execution_queue": []
 }
}