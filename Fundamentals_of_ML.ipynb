{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fundamentals of ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwMPXefxzPv/qrKTzM69Ta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Data-Science-and-Machine-Learning/blob/master/Fundamentals_of_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz4WV5XewFfc",
        "colab_type": "text"
      },
      "source": [
        "## A gentle journey from linear regression to neural networks\n",
        "\n",
        "Based on the article by Joseph Rocca. [Article link](https://towardsdatascience.com/a-gentle-journey-from-linear-regression-to-neural-networks-68881590760e)\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Our goal here is more to make the main guideline as clear as possible than to obstruct the reader comprehension with some technical details (that can be, nevertheless, very interesting). Especially, we will go from simple problems to more difficult ones in order to show, along the way, how neural networks naturally (at least in the spirit) extend some well known techniques. Obviously, on our way, we will have to make some simplifications or to omit some details. We apologise in advance if it can be, at some points, frustrating for the more advanced readers.\n",
        "\n",
        "\n",
        "> **We introduce the fact that more advanced models, with better predictive power, often come at the price of some higher difficulties in optimisation or interpretability of the model and then discuss briefly these two questions.** - Lead into SHAP values through this point\n",
        "\n",
        "> After RFs, now you can see things are getting complicated here - as things become more complex we kind of lose sense of the business context. The models become more and more like a black box. Think a simple DT - how can u quantify FA? - simple ans: how many times a node is being split, but that alone is not enough\n",
        "\n",
        "```\n",
        "ML explanation - I am not going to bore you with quotes, definitions and complicated venn diagrams- lets look at it through an example\n",
        "\n",
        "prob: understand if you will come to the event?\n",
        "\n",
        "Features - Survey -> NLP _> Sentiment analysis\n",
        "Day, is_weekday? occupation? Age? gender? (bias) ethnicity(bias), occupation\n",
        "\n",
        "Think about it like a cloud in the moddle with lines popping out one by one through animation \n",
        "\n",
        "Poster - > CNN _ computer vision\n",
        "\n",
        "Maybe after understanding these features u see a definite trend - People with ages > 50 - less likely - advertise to them separately - clustering\n",
        "\n",
        "Color code separately on what sparbox uses (?)\n",
        "\n",
        "We can extend the same to retailers - how to predict the sales - features will change\n",
        "```\n",
        "\n",
        "> Bias - [Lindsay Elizabeth's answer](https://www.quora.com/What-is-the-scariest-aspect-of-artificial-intelligence)\n",
        "\n",
        "Arthur Samuel, pioneer in the field of computer gaming and artificial intelligence, defined Machine Learning (ML) as the field of study that gives computers the ability to learn without being explicitly programmed. In other words, whatever the purpose of our algorithm is, the rules to achieve this goal are not explicitly programmed but are “learned” (and we will come back to this word later) by the computer, based on some useful data. This is the big difference with a classical algorithm.\n",
        "In a classical algorithm, rules are explicitly given to the computer to perform a task. In a machine learning algorithm, a model (parametrized or not) that define a family of possible rules is given to the computer along with a whole bunch of data and a strategy to find the better rules among the possible ones based on these data (optimisation). In the next paragraph we will explicit all these elements in one of the most basic machine learning models that exist: the linear regression.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AExtEokr8EGT",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "\n",
        "ML - Supervised and Unsupervised\n",
        "\n",
        "Lets say you have to predict the sales of this coat at the end of 1 week\n",
        "\n",
        "Simple features - price discount is it on discount or not - categorical/continuous - models cannot undertsand cat features - encoding\n",
        "\n",
        "Day of the week - SUnday close to Monday (cyclic enc) is_weekend, is_holiday - fetaure engg - when u create new features out of already existing ones\n",
        "\n",
        "\n",
        "what is NN - function approximator. U ha\n",
        "\n",
        "Product image - color, buttons - CNN - [how to describe] - think of it as a function approxiamtor? CNN is a special NN that can work on detecting visual features - say cat , first it will detect edges, shape, color (animal) then it will detect whiskers, eyes (cat) - and all these visual features are learned dynamically \n",
        "\n",
        "Feature engg - price elasticity\n",
        "\n",
        "Demographics - clustering - similar stores maybe products sell similarly\n",
        "\n",
        "Product details - [NLP] - keywords: 'sale' 'limited' 'deal', we cant simply hardcode them. Deal might have synonyms i.e offers\n",
        "\n",
        "\n",
        "We get a consolidated set of features for each such product and we provide them to the model and it comes up with a prediction \n",
        "\n",
        "This is just an example of how we can leverage various aspects of AI - each of these sub fields - like NLP, Comp Vision is an entire field in itself\n",
        "\n",
        "\n",
        "How - next slide\n",
        "\n",
        "RF - each DT works on a subset of features. So u can imagine one that understand the inventory aspects, one that understand demographics and competitor aspects, one that understands the image features and by aggregating results across all these 100s of trees we reach an appropriate prediction\n",
        "\n",
        "\n",
        "If we observe that in general because of the inventory related features the sales are getting lowered we can provide them with additional business recommendations - think of it like a recommender system for features\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viBlLflsn0MV",
        "colab_type": "text"
      },
      "source": [
        "### What is the role of the bias in neural networks?\n",
        "\n",
        "I'm aware of the gradient descent and the back-propagation algorithm. What I don't get is: when is using a bias important and how do you use it?\n",
        "\n",
        "For example, when mapping the AND function, when I use 2 inputs and 1 output, it does not give the correct weights, however, when I use 3 inputs (1 of which is a bias), it gives the correct weights.\n",
        "\n",
        "[link on StackOverflow](https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks)\n",
        "\n",
        "> [Answer by Nate Kohl](https://stackoverflow.com/users/98654/nate-kohl)\n",
        "\n",
        "I think that biases are almost always helpful. In effect, a bias value allows you to shift the activation function to the left or right, which may be critical for successful learning.\n",
        "\n",
        "It might help to look at a simple example. Consider this 1-input, 1-output network that has no bias:\n",
        "\n",
        "\n",
        "\n",
        "![](https://i.stack.imgur.com/bI2Tm.gif)\n",
        "\n",
        "The output of the network is computed by multiplying the input (x) by the weight (w0) and passing the result through some kind of activation function (e.g. a sigmoid function.)\n",
        "\n",
        "Here is the function that this network computes, for various values of w0:\n",
        "\n",
        "\n",
        "![](https://i.stack.imgur.com/ddyfr.png)\n",
        "\n",
        "Changing the weight w0 essentially changes the \"steepness\" of the sigmoid. That's useful, but what if you wanted the network to output 0 when x is 2? Just changing the steepness of the sigmoid won't really work -- you want to be able to shift the entire curve to the right.\n",
        "\n",
        "\n",
        "That's exactly what the bias allows you to do. If we add a bias to that network, like so:\n",
        "\n",
        "![](https://i.stack.imgur.com/oapHD.gif)\n",
        "\n",
        "\n",
        "then the output of the network becomes sig(w0*x + w1*1.0). Here is what the output of the network looks like for various values of w1:\n",
        "\n",
        "![](https://i.stack.imgur.com/t2mC3.png)\n",
        "\n",
        "\n",
        "\n",
        "Having a weight of -5 for w1 shifts the curve to the right, which allows us to have a network that outputs 0 when x is 2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyaUssQgv9p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}