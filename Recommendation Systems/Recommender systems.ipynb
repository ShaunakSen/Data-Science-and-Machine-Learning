{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Recommender systems - understanding the basics\n\n> Notes on the lecture series by Machine Learning at VU University Amsterdam: https://mlvu.github.io/\n\n---",
   "metadata": {
    "tags": [],
    "cell_id": "00000-4f444cc4-ead7-4286-b3ff-c525cdeedfa5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Introduction\n\n### The Netflix task\n\nThe Netflix task was a milestone in ML challenges and had a significant impact in developing future platforms like Kaggle\n\n\n#### Collaborative filtering\n\n- Source of data: explicit user ratings; we ask users which movies they like/dislike and we have a small data set\n- Based on this explicit feedback we have to predict ratings for new movies\n- This is based on __explicit feedback__. The users collaborate together to provide ratings to help filter movies that they like\n- The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person. For example, a collaborative filtering recommendation system for preferences in television programming could make predictions about which television show a user should like given a partial list of that user's tastes (likes or dislikes). Note that these predictions are specific to the user, but use information gleaned from many users. \n- The main drawback is that information is very __sparse__. We might only have few ratings/no ratings per user\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00001-536cc336-296f-4ceb-8a1b-7dc2a8294173",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### The recommendation task\n\nThe recommendation task is applicable when the problem follows this framework:\n\n- We have 2 large sets of things and a particular relation bw them; eg: user liked movie OR user bought book OR user rated movie 2 out of 5\n- Often the sides are set of users and a set of items. But this is not necessary; for example recipes and ingredients with the property \"has_ingredient\". Also based on which politician voted for which law, we can make an analysis of general voting behaviors by elected officials\n- It might be that the left and right items are the same set; eg: which people should be friends\n- Key property: u have no info/features about the 2 sets of items, we only know of the relationship which exists. If we do have some fetaures we consider them secondary information. We want to base our predictions primarily on the property linking the 2 classes of objects\n\n![](https://i.imgur.com/n47BOm6.png)\n\n![](https://i.imgur.com/DNFKzBZ.png)\n\nIn most social media sites like FB, YouTube, Twitter, the main content which we find on the site is powered by recommendations\n",
   "metadata": {
    "tags": [],
    "cell_id": "00002-33006e50-7f23-4afb-831a-92c02c4c7889",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Representing the problem\n\nLet us consider the movie recommendation example. We have numeric ratings, which may be -ve signifying that the user dislikes the movie\nThis is the easiest setting to have. We can visualize our problem set as a matrix R of users and which movies they have rated and how\n\nWe can see that this is a sparse matrix and we do not have any features of the users/movies\n\n![](https://i.imgur.com/bQSttPB.png)\n\n#### Embedding vectors\n\nIn the word embedding problem, we represented each word by a vector and learned the values in the vectors \n\nHere also we do the same\n\n- we assign vector with initially random numbers to each user and movie\n- the dimension for each vector k needs to be same for each user and movie\n- we arrange the embedding vectors into matrices where each col represents a user/movie\n\n![](https://i.imgur.com/AGtEh5s.png)\n\nNow imagine we have to solve this problem ourselved, we could start by crafting some features of a movie and user\nFor e.g: `likes_romance, likes_action` etc. Also the features in movies are like `has_romance, has_action` etc.\n\n`score(u, m) -> high +ve no if user would like the movie, high -ve if user will dislike the movie, low value if user is mostly ambivalent about the movie`\n\nOne such scoring function is the dot product bw the user embedding vector and the movie embedding vector:\n\n![](https://i.imgur.com/KA4DMSb.png)\n\nSo if we denote the user embedding metrix as U and movie embedding matrix as M\n\nU^T.M -> R\n\nSay num_users -> n_u and num_movies is n_m. Say embedding vector size -> n_u x n_m\n\n![](https://i.imgur.com/AtoBr4H.jpeg)\n\n![](https://i.imgur.com/NXRCrVi.jpeg)\n\n![](https://i.imgur.com/dAONcD8.png)\n\nThe above is a matrix for every single user-movie pair in our data\n\n\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00003-c4720bd9-1a12-42a5-b60a-fbada0cd67a5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Recommender sys as Matrix Decomposition/Optimzation Problem\n\nIn the above explanation we saw that if we have movie features and user features, we cab construct a prediction for how much will a user like a movie\n\nSo if we look at the problem the other way around\n\n- Given a rating matrix R, __decompose it as a product of 2 factors U and M.__ \n- If we find U and M st U^T . M is close to R, then we can assume that __the matrices U and M contain meaninful embeddings for this use case__\n- This is called __Matrix Factorization/Decomposition__ approach to Recommender systems\n\n![](https://i.imgur.com/N4JQNy4.png)\n\nIf we look at the last line, u_i . m_j is sumply the dot prod to compute pred rating, we subtract with the given rating to get error and simply square it\n\nWe sum this for all and simply optimize for U and M which gives us the least error\n\n#### Challenges\n\n- Lot of missing values in R\n- If we fill in with 0 we are essentially telling our model to predict 0 ratings for these unkown values, which is not refelective of the true rating\n\n#### Solution\n\n![](https://i.imgur.com/DgH3GYv.png)\n\nHere i and j iterate only over those elems in the matrix for which we know the rating\n\nThis makes optimization a bit more difficult but leads to better models\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00004-3f8d623a-fa52-4118-94df-de974009dbdf",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Solving the optimization problem\n\nObvious soln will be to use Gradient Descent\n\nOr we can use something called alternating optimization\n\n#### Alternating Least Squares\n\n![](https://i.imgur.com/vKMpyIj.png)\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00005-59b588e1-ef84-41da-85e0-d545d1a45e15",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Solution walkthrough\n\n\n<img src=\"https://i.imgur.com/b41meOm.jpeg\" width=800 height=800>\n\n\n<img src=\"https://i.imgur.com/QW6rT40.jpeg\" width=800 height=800>\n\n\n<img src=\"https://i.imgur.com/fGNJlXs.jpeg\" width=800 height=800>\n\n\n<img src=\"https://i.imgur.com/9HIDGhX.jpeg\" width=800 height=800>\n\n\n`E_lj is a scalar so E_l is a vector of [E_l1, E_l2, ... E_lm]`\n\n<img src=\"https://i.imgur.com/s6z3Gi4.jpeg\" width=800 height=800>\n\n\n> Note the use of dot (.) at E_l. this indicates that its [E_l1, E_l2, ... E_lm] ie vector of errors for lth user wrt each of the m movies\n\nEach such element can be computed from eqn 1\n\n`E_l_i = R_l_i - u_l . m_i`\n\nThus the gradient update for a user weight can be computed using the last eqn of the above image\n\n---",
   "metadata": {
    "tags": [],
    "cell_id": "00006-01462ec2-8e9b-47dc-9596-8db19c5ed331",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=00b6f2e0-e86b-4758-8c53-b9ea709d832e' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "9569a4b1-8251-4f7a-b6b0-ace291d7444e",
  "deepnote_execution_queue": []
 }
}