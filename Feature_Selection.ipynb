{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Data-Science-and-Machine-Learning/blob/master/Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaK70zpxS779",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection For Machine Learning in Python\n",
        "\n",
        "[tutorial link](https://machinelearningmastery.com/feature-selection-machine-learning-python/)\n",
        "\n",
        "The data features that you use to train your machine learning models have a huge influence on the performance you can achieve.\n",
        "\n",
        "Irrelevant or partially relevant features can negatively impact model performance.\n",
        "\n",
        "In this post you will discover automatic feature selection techniques that you can use to prepare your machine learning data in python with scikit-learn.\n",
        "\n",
        "Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression.\n",
        "\n",
        "Three benefits of performing feature selection before modeling your data are:\n",
        "\n",
        "- Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n",
        "- Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
        "- Reduces Training Time: Less data means that algorithms train faster.\n",
        "\n",
        "\n",
        "### 1. Univariate Selection\n",
        "\n",
        "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
        "\n",
        "The scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features.\n",
        "\n",
        "The example below uses the chi squared (chi^2) statistical test for non-negative features to select 4 of the best features from the Pima Indians onset of diabetes dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGQUOz1SS6XO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "190c07bd-ebdf-4fa6-ec3e-e21aad4abf7e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# load data\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "dataframe = pd.read_csv(url, names=names)\n",
        "\n",
        "dataframe.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>test</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
              "0     6   148    72    35     0  33.6  0.627   50      1\n",
              "1     1    85    66    29     0  26.6  0.351   31      0\n",
              "2     8   183    64     0     0  23.3  0.672   32      1\n",
              "3     1    89    66    23    94  28.1  0.167   21      0\n",
              "4     0   137    40    35   168  43.1  2.288   33      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tii6jY7xUFkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3296974a-e876-4f2d-f878-ff5980c5e34e"
      },
      "source": [
        "array = dataframe.values\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n",
        "\n",
        "print (X[:10])\n",
        "\n",
        "print (Y[:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
            "  5.000e+01]\n",
            " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
            "  3.100e+01]\n",
            " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
            "  3.200e+01]\n",
            " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01]\n",
            " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
            "  3.000e+01]\n",
            " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
            "  2.600e+01]\n",
            " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
            "  2.900e+01]\n",
            " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
            "  5.300e+01]\n",
            " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
            "  5.400e+01]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrqjZTnyUne_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8d721cdf-79b8-4dde-ab97-efe05c062811"
      },
      "source": [
        "# feature extraction\n",
        "\n",
        "test = SelectKBest(score_func=chi2, k=4)\n",
        "fit = test.fit(X, Y)\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "\n",
        "# summarize scores\n",
        "\n",
        "print (fit.scores_)\n",
        "top_k_col_idx = np.argsort(-fit.scores_)[:4]\n",
        "\n",
        "print (\"The top {} features are:\".format(4))\n",
        "\n",
        "for x in top_k_col_idx:\n",
        "  print (dataframe.columns[x])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n",
            "The top 4 features are:\n",
            "test\n",
            "plas\n",
            "age\n",
            "mass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2N9FnuLga5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf86c964-cd0a-4299-9c5a-8df3d9ad2bc4"
      },
      "source": [
        "\"\"\"\n",
        "Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables. \n",
        "It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
        "\"\"\"\n",
        "\n",
        "mutual_info_regression(X, Y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.006, 0.132, 0.03 , 0.038, 0.029, 0.074, 0.009, 0.021])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "057xztRbhA-3",
        "colab_type": "text"
      },
      "source": [
        "### 2. Recursive Feature Elimination\n",
        "\n",
        "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and building a model on those attributes that remain.\n",
        "\n",
        "It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.\n",
        "\n",
        "The example below uses RFE with the logistic regression algorithm to select the top 3 features. The choice of algorithm does not matter too much as long as it is skillful and consistent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53SBSz-KhLS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}