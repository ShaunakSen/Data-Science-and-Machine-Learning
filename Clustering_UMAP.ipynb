{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering - UMAP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Data-Science-and-Machine-Learning/blob/master/Clustering_UMAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVM3PCONh_aF",
        "colab_type": "text"
      },
      "source": [
        "## Using UMAP for Clustering\n",
        "\n",
        "[link](https://umap-learn.readthedocs.io/en/latest/clustering.html)\n",
        "\n",
        "UMAP can be used as an effective preprocessing step to boost the performance of density based clustering. UMAP, like t-SNE, can also create tears in clusters that are not actually present, resulting in a finer clustering than is necessarily present in the data. Despite these concerns there are still valid reasons to use UMAP as a preprocessing step for clustering. As with any clustering approach one will want to do some exploration and evaluation of the clusters that come out to try to validate them if possible.\n",
        "\n",
        "First we’ll need a selection of libraries loaded up. Obviously we’ll need data, and we can use sklearn’s fetch_mldata to get it. We’ll also need the usual tools of numpy, and plotting. Next we’ll need umap, and some clustering options. Finally, since we’ll be working with labeled data, we can make use of strong cluster evaluation metrics Adjusted Rand Index and Adjusted Mutual Information.\n",
        "\n",
        "### Rand Index\n",
        "\n",
        "[link](https://davetang.org/muse/2017/09/21/the-rand-index/)\n",
        "\n",
        "![](https://s0.wp.com/latex.php?latex=R+%3D+%5Cfrac%7Ba+%2B+b%7D%7B+%7B%7Bn%7D%5Cchoose%7B2%7D%7D+%7D+&bg=ffffff&fg=000&s=0)\n",
        "\n",
        "The a  in the formula refers to the number of times a pair of elements belongs to a same cluster across two different clustering results and the b  refers to the number of times a pair of elements are in different clusters across two different clustering results. \n",
        "\n",
        "Say we have a set of six elements: {a, b, c, d, e, f}. Clustering method 1 (CM1) forms three clusters; the first two items are in group 1, the third and fourth are in group 2, and the fifth and sixth are in group 3: {1, 1, 2, 2, 3, 3}. Clustering method 2 (CM2) forms two clusters; the first three items are in group 1 and the last three items are in group 2: {1, 1, 1, 2, 2, 2}. What’s the Rand index of these two clustering results?\n",
        "\n",
        "To manually calculate the Rand index, we need to go through every unordered pair to work out a  and b ; let’s work out a  first. There are 15 unordered pairs in a set of six elements: {a, b}, {a, c}, {a, d}, {a, e}, {a, f}, {b, c}, {b, d}, {b, e}, {b, f}, {c, d}, {c, e}, {c, f}, {d, e}, {d, f}, and {e, f}. a  is every time a pair of elements is grouped together by the two clustering methods. {a, b} and {e, f} are clustered together by CM1 and CM2, so a  = 2. b  is every time a pair of elements is not grouped together by the two clustering methods. {a, d}, {a, e}, {a, f}, {b, d}, {b, e}, {b, f}, {c, e}, and {c, f} are not clustered together by CM1 and CM2, so b  = 8. a  and b  are the times that both clustering methods agree. Therefore, the Rand index is:\n",
        "\n",
        "\n",
        "![](https://s0.wp.com/latex.php?latex=R+%3D+%5Cfrac%7B2+%2B+8%7D%7B+%7B%7B6%7D%5Cchoose%7B2%7D%7D%7D+%3D+%5Cfrac%7B10%7D%7B15%7D+%3D+0.667+&bg=ffffff&fg=000&s=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IonHzM0i8zo",
        "colab_type": "code",
        "outputId": "e2983a70-a52f-4788-f953-dd91feeef91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "!pip install hdbscan"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hdbscan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/35/a117860dd7f38eb1a77e4e30ac69a63c45c5a6356f503874fbe80fc464b7/hdbscan-0.8.23.tar.gz (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 9.5MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.12.0)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.17.4)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.29.14)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.23-cp36-cp36m-linux_x86_64.whl size=2332155 sha256=0274d90061122aea0b6aeea66e4d46a6653ce0e3678d026cee3eb25da5094194\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/2a/69/0cdd5414624312666718f7526b0ab39cad65cea1c1b3892768\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm0s88rGh8mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# Dimension reduction and clustering libraries\n",
        "import umap\n",
        "import hdbscan\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE_9XON2xxli",
        "colab_type": "text"
      },
      "source": [
        "Now let’s set up the plotting and grab the data we’ll be using – in this case the MNIST handwritten digits dataset. MNIST consists of 28x28 pixel grayscale images of handwritten digits (0 through 9). These can be unraveled such that each digit is described by a 784 dimensional vector (the gray scale value of each pixel in the image). Ideally we would like the clustering to recover the digit structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a_sgzWnk01h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style='white', rc={'figure.figsize':(10,8)})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrpxIjjTx23K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mnist = fetch_openml(name='mnist_784')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fgWSxZLz_9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a52694e0-f994-4e42-d5da-205ccd670006"
      },
      "source": [
        "mnist.target"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}