{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Data Processing\n",
    "\n",
    "## Task 1\n",
    "This coursework will assess your understanding of using NoSQL to store and retrieve data.  You will perform operations on data from the Enron email dataset in a MongoDB database, and write a report detailing the suitability of different types of databases for data science applications.  You will be required to run code to answer the given questions in the Jupyter notebook provided, and write a report describing alternative approaches to using MongoDB.\n",
    "\n",
    "Download the JSON version of the Enron data (using the “Download as zip” to download the data file from http://edshare.soton.ac.uk/19548/, the file is about 380MB) and import into a collection called messages in a database called enron.  You do not need to set up any authentication.  In the Jupyter notebook provided, perform the following tasks, using the Python PyMongo library.\n",
    "\n",
    "Answers should be efficient in terms of speed.  Answers which are less efficient will not get full marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "\n",
    "The JSON version of the dataset has been downloaded from [this link](http://edshare.soton.ac.uk/19548/)\n",
    "\n",
    "The dataset has been imported into the database **enron**\n",
    "\n",
    "The name of the collection is **messages**\n",
    "\n",
    "**100000** documents have been imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE CODE TO IMPORT FULL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-08T19:40:19.811+0000\tconnected to: localhost\n",
      "2018-12-08T19:40:19.811+0000\tdropping: enron_short.messages\n",
      "2018-12-08T19:40:22.810+0000\t[######..................] enron_short.messages\t94.5MB/354MB (26.7%)\n",
      "2018-12-08T19:40:25.811+0000\t[#############...........] enron_short.messages\t201MB/354MB (56.8%)\n",
      "2018-12-08T19:40:28.810+0000\t[###################.....] enron_short.messages\t290MB/354MB (82.0%)\n",
      "2018-12-08T19:40:31.810+0000\t[######################..] enron_short.messages\t329MB/354MB (92.9%)\n",
      "2018-12-08T19:40:34.478+0000\t[########################] enron_short.messages\t354MB/354MB (100.0%)\n",
      "2018-12-08T19:40:34.478+0000\timported 100000 documents\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# mongoimport is the Mongo command to import data.  \n",
    "# It specifies the database, collection and format, and import file\n",
    "# --drop means it's going to drop any collection with the same name which already exists\n",
    "mongoimport --db enron_short --collection messages --drop --file ./messages_short.json\n",
    "# Delete the JSON file we just downloaded\n",
    "rm ./messages_short.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'enron_short', 'local']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)\n",
    "Write a function which returns a MongoDB connection object to the \"messages\" collection. [4 points] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change DB Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_collection",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "db_name = 'enron_short'\n",
    "coll_name = 'messages'\n",
    "\n",
    "def get_collection():\n",
    "    \"\"\"\n",
    "    Connects to the server, and returns a collection object\n",
    "    of the `messages` collection in the `enron` database\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    client = MongoClient('mongodb://localhost:27017')\n",
    "    \n",
    "    # check if the database is present\n",
    "    if db_name in client.list_database_names():\n",
    "        db = client[db_name]\n",
    "        # check if collection is present\n",
    "        if coll_name in db.list_collection_names():\n",
    "            collection = db[coll_name]\n",
    "        else:\n",
    "            print(\"Collection:\", coll_name, \"not found\")\n",
    "            return False\n",
    "    else:\n",
    "        print (\"Database:\", db_name, \"not found\")\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    return collection\n",
    "            \n",
    "        \n",
    "messages_collection = get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying that collection connection is able to read all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_collection.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)\n",
    "\n",
    "Write a function which returns the amount of emails in the messages collection in total. [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_amount_of_messages",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "def get_amount_of_messages(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the amount of documents in the collection\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    return collection.count_documents({})\n",
    "number_of_emails = get_amount_of_messages(messages_collection)    \n",
    "\n",
    "print (number_of_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) \n",
    "\n",
    "Write a function which returns each person who was BCCed on an email.  Include each person only once, and display only their name according to the X-To header. [4 points] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_bcced_people",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Villarreal, Alex',\n",
       " 'Vuittonet, Laura',\n",
       " 'Wood, Kim',\n",
       " 'Choate, Heather',\n",
       " 'Rangel, Ina',\n",
       " 'Hogan, Irena D.',\n",
       " 'Westbrook, Cherylene R.',\n",
       " 'De La Paz, Janet',\n",
       " 'Beck, Sally',\n",
       " 'Denny, Jennifer',\n",
       " 'Piper, Greg',\n",
       " 'Patti Thompson',\n",
       " 'Robert Superty',\n",
       " 'Beth Apollo',\n",
       " 'Greg Piper',\n",
       " 'Apollo, Beth',\n",
       " 'Barry, Patrick',\n",
       " 'Blair, Jean',\n",
       " 'Bryan, Randy',\n",
       " 'Callans, Nancy',\n",
       " 'Carr, James',\n",
       " 'Clapper, Karen',\n",
       " 'Perry, Renee',\n",
       " 'Porter, Diana',\n",
       " 'Walden, Shirley',\n",
       " 'Washington, Kathy',\n",
       " 'Causey, Richard',\n",
       " 'Dyson, Fernley',\n",
       " 'Jordan, Mike',\n",
       " 'Lokey, Teb',\n",
       " 'Ratliff, Dale',\n",
       " 'Shapiro, Richard',\n",
       " 'Dernehl, Ginger',\n",
       " 'Guerrero, Janel',\n",
       " 'Steffes, James D.',\n",
       " 'Richard Shapiro',\n",
       " 'James D Steffes',\n",
       " 'Susan J Mara',\n",
       " 'Harry Kingerski',\n",
       " 'hgovenar',\n",
       " 'Scott Govenar',\n",
       " 'Davis, Dana',\n",
       " 'Ogenyi, Gloria',\n",
       " 'Collins, Harry',\n",
       " 'Cooley, Jan',\n",
       " 'Johnson, Jan',\n",
       " 'McBride, Jane',\n",
       " 'Wilson, Jane',\n",
       " 'Butler, Janet',\n",
       " 'Place, Janet',\n",
       " 'Moore, Janice',\n",
       " 'Desrochers, Jim',\n",
       " 'Lamb, John',\n",
       " 'Novak, John',\n",
       " 'Schwartzenburg, John',\n",
       " 'Viverito, John',\n",
       " 'Murray, Julia',\n",
       " 'Delahay, Julie',\n",
       " 'Boyd, Justin',\n",
       " 'Jones, Karen E.',\n",
       " 'Azevedo, Karla',\n",
       " 'Cole, Kate',\n",
       " 'Carnahan, Kathleen',\n",
       " 'Sullivan, Kathleen',\n",
       " 'Young, Kay',\n",
       " 'Leibman, Lara',\n",
       " 'Bishop, Larry',\n",
       " 'Pardue, Larry',\n",
       " 'Hagerty, Lauren',\n",
       " 'Mayer, Laurie',\n",
       " 'Kasbekar, Lena',\n",
       " 'Guinn, Linda',\n",
       " 'Mellencamp, Lisa',\n",
       " 'Robichaux, Lisa',\n",
       " 'Nettelton, Marcus',\n",
       " 'Trevino, Maricela',\n",
       " 'Haedicke, Mark',\n",
       " 'Evans, Mark',\n",
       " 'Greenberg, Mark',\n",
       " 'Holsworth, Mark',\n",
       " 'Powell, Mark',\n",
       " 'Taylor, Mark',\n",
       " 'Braddy, Martha',\n",
       " 'Cook, Mary',\n",
       " 'Oscar, Mary Denise',\n",
       " 'Heinitz, Mary',\n",
       " 'Ogden, Mary',\n",
       " 'Dawson, Matthew',\n",
       " 'Lee, Matthias',\n",
       " 'Robison, Michael',\n",
       " 'Smalling, Michael J.',\n",
       " 'Cash, Michelle',\n",
       " 'Robertson, Audrey',\n",
       " 'Wehring, Linda',\n",
       " 'Storey, Geoff',\n",
       " 'Gilbert-smith, Doug',\n",
       " 'Twiggs, Thane']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bcced_people(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the names of the people who have received an email by BCC\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # lists to store intermediate output\n",
    "    bcc_list = []\n",
    "    bcc_list1 = []\n",
    "    bcc_list2 = []\n",
    "    bcc_list3 = []\n",
    "    \n",
    "    \n",
    "    # final list of names\n",
    "    final_list = []\n",
    "\n",
    "    # find docs where bcc field exists and is not empty and append in the list: bcc_list\n",
    "\n",
    "    for doc in collection.find({ 'headers.X-bcc': {'$exists': True, '$ne': ''} }):\n",
    "        bcc_list.append(doc['headers']['X-bcc'])\n",
    "\n",
    "\n",
    "    # set of operations to clean the data\n",
    "\n",
    "    for bcc_value in bcc_list:\n",
    "        bcc_list1.append(bcc_value.split('>,'))\n",
    "\n",
    "\n",
    "\n",
    "    for bcc_value in bcc_list1:\n",
    "        for value in bcc_value:\n",
    "            bcc_list2.append(value.split('</O')[0])\n",
    "\n",
    "\n",
    "    for bcc_value in bcc_list2:\n",
    "        bcc_list3.append(bcc_value.split(' <')[0])\n",
    "\n",
    "    # now we have set of names and emails without the part between '<>'\n",
    "\n",
    "    # we want only the names\n",
    "\n",
    "    for bcc_value in bcc_list3:\n",
    "        # ignore the email ids\n",
    "        if '@' not in bcc_value:\n",
    "            # strip the names of trailing whitespaces and check if the names are already in the final list \n",
    "            if bcc_value.strip() not in final_list:\n",
    "                final_list.append(bcc_value.strip())\n",
    "\n",
    "    return final_list\n",
    "get_bcced_people(messages_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following questions I have used the **Aggregation Pipeline** framework of MongoDB to process and aggregate the data into logical steps for easier debugging and improved performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)\n",
    "\n",
    "Write a function with parameter subject, which gets all emails in a thread with that parameter, and orders them by date (ascending). “An email thread is an email message that includes a running list of all the succeeding replies starting with the original email.”, check for detail descriptions at https://www.techopedia.com/definition/1503/email-thread [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_emails_in_thread",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Tue, 14 Nov 2000 04:17:00 -0800 (PST)',\n",
      " 'Subject': 'Plays and other information',\n",
      " 'body': 'I know I might seem a little obsessed with this, but here are some '\n",
      "         'of our \\n'\n",
      "         'plays from our flag football league.  There are plays on both tabs.\\n'\n",
      "         'I was thinking that we would start with me at left flanker, Paul '\n",
      "         'Broderick at \\n'\n",
      "         'center, Paul Burkhart at right slot, Steve at right flanker, Sarah '\n",
      "         'at \\n'\n",
      "         'blocker, and either Mike or Chris at blocker.  Let me know if you '\n",
      "         'have \\n'\n",
      "         'objections.  Also, I am sending this to Paul Burkhart so I am '\n",
      "         'assuming that \\n'\n",
      "         'he will play (P. Broderick can you confirm this?).\\n'\n",
      "         '\\n'\n",
      "         'Steve - if you have some plays from your team that you think might '\n",
      "         'work let \\n'\n",
      "         'me know.\\n'\n",
      "         '\\n'\n",
      "         'Let me know what you think.\\n'\n",
      "         '\\n'\n",
      "         \"Hook 'Em!\\n\"\n",
      "         '-Eric\\n'\n",
      "         '\\n'\n",
      "         '\\n',\n",
      " 'filename': '77.'}\n",
      "{'Date': 'Tue, 14 Nov 2000 07:37:00 -0800 (PST)',\n",
      " 'Subject': 'Re: Plays and other information',\n",
      " 'body': 'suggestion... make a playbook that just shows individual routes.. '\n",
      "         'that way \\n'\n",
      "         'Luis can just customize  in the huddle....\\n'\n",
      "         '\\n'\n",
      "         'Ex.   outs, curls, out-and-up, post..  etc...     \\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         'also,,    You give routes to the linemen and they should block  and '\n",
      "         'then roll \\n'\n",
      "         'out into the open flats once the defense goes past.... \\n'\n",
      "         '\\n'\n",
      "         'AND... most importantly.. how did you  draw those plays  excel....\\n'\n",
      "         '\\n',\n",
      " 'filename': '451.'}\n",
      "{'Date': 'Tue, 14 Nov 2000 08:00:00 -0800 (PST)',\n",
      " 'Subject': 'Re: Plays and other information',\n",
      " 'body': \"we will have a list of patterns just in case people don't know what \"\n",
      "         'they are, \\n'\n",
      "         'but the plays are designed to clear out areas so that certain '\n",
      "         'patterns are \\n'\n",
      "         'more open.\\n'\n",
      "         'you can draw plays in excel using the drawing toolbar.\\n'\n",
      "         '\\n'\n",
      "         'what time are we going to scrimmage tomorrow?\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         'Michael Simmons\\n'\n",
      "         '11/14/2000 03:37 PM\\n'\n",
      "         'To: Eric Bass/HOU/ECT@ECT\\n'\n",
      "         'cc:  \\n'\n",
      "         'Subject: Re: Plays and other information  \\n'\n",
      "         '\\n'\n",
      "         'suggestion... make a playbook that just shows individual routes.. '\n",
      "         'that way \\n'\n",
      "         'Luis can just customize  in the huddle....\\n'\n",
      "         '\\n'\n",
      "         'Ex.   outs, curls, out-and-up, post..  etc...     \\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         'also,,    You give routes to the linemen and they should block  and '\n",
      "         'then roll \\n'\n",
      "         'out into the open flats once the defense goes past.... \\n'\n",
      "         '\\n'\n",
      "         'AND... most importantly.. how did you  draw those plays  excel....\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n',\n",
      " 'filename': '74.'}\n",
      "{'Date': 'Tue, 14 Nov 2000 08:22:00 -0800 (PST)',\n",
      " 'Subject': 'Re: Plays and other information',\n",
      " 'body': 'the scrimmage is still up in the air...\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         'webb said that they didnt want to scrimmage...\\n'\n",
      "         '\\n'\n",
      "         'the aggies  are scrimmaging each other... (the aggie teams practiced '\n",
      "         'on \\n'\n",
      "         'Sunday)\\n'\n",
      "         '\\n'\n",
      "         'when I called the aggie captains to see if we could use their '\n",
      "         'field.... they \\n'\n",
      "         'said that it was tooo smalll for us to use...\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         'sounds like bullshit to me... but what can we do....\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         'anyway... we will have to do another practice Wed. night....    and '\n",
      "         \"I dont' \\n\"\n",
      "         'know where we can practice.... any suggestions...\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         'also,  we still need one  more person...',\n",
      " 'filename': '450.'}\n",
      "{'Date': 'Tue, 14 Nov 2000 23:42:00 -0800 (PST)',\n",
      " 'Subject': 'Re: Plays and other information',\n",
      " 'body': 'Hey Paul,\\n'\n",
      "         '\\n'\n",
      "         'I left a msg in your voice mail, but the low down is that the ENE/AC '\n",
      "         'Flag \\n'\n",
      "         'Football tourney is Saturday and we would like you to play.  The '\n",
      "         'tourney \\n'\n",
      "         'starts at 10 and is 3 hours long.  If we win, we get 16 tickets to '\n",
      "         'the game \\n'\n",
      "         '(2 for each of us).  Let me know if you are interested.\\n'\n",
      "         '\\n'\n",
      "         'Thanks,\\n'\n",
      "         '\\n'\n",
      "         'Eric\\n'\n",
      "         'x3-0977\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         'From: Paul Burkhart@ENRON COMMUNICATIONS on 11/14/2000 05:51 PM\\n'\n",
      "         'To: Eric Bass/HOU/ECT@ECT@ENRON\\n'\n",
      "         'cc:  \\n'\n",
      "         'Subject: Re: Plays and other information  \\n'\n",
      "         '\\n'\n",
      "         'Hope all is well.  Is this in reference to the Enron/Andersen '\n",
      "         'Consulting \\n'\n",
      "         'football game?  When is it?  Do you need me to play?  Give me a call '\n",
      "         'and we \\n'\n",
      "         'can discuss (3-9557).  \\n'\n",
      "         '\\n'\n",
      "         'Thanks,\\n'\n",
      "         '\\n'\n",
      "         'Paul\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\tEric Bass@ECT\\n'\n",
      "         '\\t11/14/00 12:17 PM\\n'\n",
      "         '\\t\\t \\n'\n",
      "         '\\t\\t To: Luis Mena/NA/Enron@Enron, Michael Simmons/HOU/ECT@ECT, Paul '\n",
      "         'J \\n'\n",
      "         'Broderick/HOU/ECT@ECT, Paul Burkhart/Enron Communications@Enron \\n'\n",
      "         'Communications, Stephen Schwarzbach/Corp/Enron@Enron, Christopher \\n'\n",
      "         'Chenoweth/NA/Enron@Enron\\n'\n",
      "         '\\t\\t cc: \\n'\n",
      "         '\\t\\t Subject: Plays and other information\\n'\n",
      "         '\\n'\n",
      "         'I know I might seem a little obsessed with this, but here are some '\n",
      "         'of our \\n'\n",
      "         'plays from our flag football league.  There are plays on both tabs.\\n'\n",
      "         'I was thinking that we would start with me at left flanker, Paul '\n",
      "         'Broderick at \\n'\n",
      "         'center, Paul Burkhart at right slot, Steve at right flanker, Sarah '\n",
      "         'at \\n'\n",
      "         'blocker, and either Mike or Chris at blocker.  Let me know if you '\n",
      "         'have \\n'\n",
      "         'objections.  Also, I am sending this to Paul Burkhart so I am '\n",
      "         'assuming that \\n'\n",
      "         'he will play (P. Broderick can you confirm this?).\\n'\n",
      "         '\\n'\n",
      "         'Steve - if you have some plays from your team that you think might '\n",
      "         'work let \\n'\n",
      "         'me know.\\n'\n",
      "         '\\n'\n",
      "         'Let me know what you think.\\n'\n",
      "         '\\n'\n",
      "         \"Hook 'Em!\\n\"\n",
      "         '-Eric\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '\\n',\n",
      " 'filename': '73.'}\n"
     ]
    }
   ],
   "source": [
    "def get_emails_in_thread(collection, subject):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return All emails in the thread with that subject\n",
    "    \"\"\" \n",
    "    \n",
    "    # The output should include all emails in the thread including the original email\n",
    "    # YOUR CODE HERE    \n",
    "    \n",
    "    output_emails = []\n",
    "    \n",
    "    # Get the main subject as parameter\n",
    "\n",
    "\n",
    "    # other mails in the thread will have the subject : 'Re: [subject]'\n",
    "    subject = subject.strip()\n",
    "\n",
    "    reply_subject = \"Re: \" + subject\n",
    "\n",
    "    # limit stage to limit results (may be added to the pipeline for debugging)\n",
    "\n",
    "    limit_stage = {\n",
    "        '$limit': 100\n",
    "    }\n",
    "\n",
    "    # This stage is to match the emails according to the subjects\n",
    "\n",
    "    match_stage = {\n",
    "        '$match': { 'headers.Subject': { '$in': [subject, reply_subject] } }\n",
    "    }\n",
    "\n",
    "    # This stage does the following operations:\n",
    "    # 1. $substr: Extracts the first 25 chars from the Date Field\n",
    "    # 2. $rtrim: removes trailing whitespace that appears if the day is a single digit number\n",
    "    # 3. $dateFromString: converts the string to a Date object, which will be used in the sorting stage\n",
    "    # I have also used this stage to display certain fields so that the output looks clean\n",
    "\n",
    "    project_stage = {\n",
    "         '$project': { 'DateOfMessage': \n",
    "                          {'$dateFromString': { 'dateString' : \n",
    "                                               { '$rtrim': {'input': {'$substr': ['$headers.Date', 0, 25] }}}\n",
    "\n",
    "                                              }\n",
    "                          },\n",
    "\n",
    "                        'filename': 1,\n",
    "                        'body': 1,\n",
    "                        'Date': '$headers.Date',\n",
    "                        'Subject': '$headers.Subject'\n",
    "                     } \n",
    "    }\n",
    "\n",
    "    # This stage sorts the docs in ascending order of Date\n",
    "\n",
    "    sort_stage = {\n",
    "        '$sort': {'DateOfMessage': 1}\n",
    "    }\n",
    "\n",
    "    #\n",
    "\n",
    "    project_stage2 = {\n",
    "        '$project': {\n",
    "            'DateOfMessage': 0,\n",
    "            '_id': 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    pipeline = [match_stage, project_stage, sort_stage, project_stage2]\n",
    "\n",
    "    # return the cursor\n",
    "    return collection.aggregate(pipeline)\n",
    "\n",
    "for doc in get_emails_in_thread(messages_collection, \"Plays and other information\"):\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)\n",
    "\n",
    "Write a function which returns the percentage of emails sent on a weekend (i.e., Saturday and Sunday) as a `float` between 0 and 1. [6 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_percentage_sent_on_weekend",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0393"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_percentage_sent_on_weekend(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return A float between 0 and 1\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # compute total number of emails in our dataset\n",
    "    \n",
    "    total_documents = float(collection.count_documents({}))\n",
    "    \n",
    "    # limit stage to limit results (may be added to the pipeline for debugging)\n",
    "\n",
    "    limit_stage = {\n",
    "        '$limit': 100\n",
    "    }\n",
    "\n",
    "    # This stage does the following operations:\n",
    "    # 1. $substr: Extracts the first 25 chars from the Date Field\n",
    "    # 2. $rtrim: removes trailing whitespace that appears if the day is a single digit number\n",
    "    # 3. $dateFromString: converts the string to a Date object\n",
    "    project_stage = {\n",
    "         '$project': { 'DateOfMessage': \n",
    "                          {'$dateFromString': { 'dateString' : \n",
    "                                               { '$rtrim': {'input': {'$substr': ['$headers.Date', 0, 25] }}}\n",
    "\n",
    "                                              }\n",
    "                          }\n",
    "                     } \n",
    "    }\n",
    "    \n",
    "    \n",
    "    # This stage computes the day of the week for a date as a number between 1 (Sunday) and 7 (Saturday)\n",
    "    project_stage2 = {\n",
    "         '$project': {\n",
    "                        'DayOfWeek': {\n",
    "                            '$dayOfWeek': '$DateOfMessage'\n",
    "                        }\n",
    "                     } \n",
    "    }\n",
    "    \n",
    "\n",
    "    # This stage is used to filter docs sent on Sunday(1) or Saturday(7)\n",
    "    match_stage1 = {\n",
    "            '$match': { 'DayOfWeek': { '$in': [1, 7] } }\n",
    "    }\n",
    "\n",
    "    # Group stage to count the number of documents\n",
    "    group_stage1 = {\n",
    "        '$group': {\n",
    "            '_id': None, 'count': {'$sum': 1}\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # final project stage to compute percentage of emails sent on weekends    \n",
    "    project_stage4 = {\n",
    "        '$project': {\n",
    "            'percentage_weekend': { '$divide': ['$count', total_documents] }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pipeline = [project_stage, project_stage2, match_stage1, group_stage1, project_stage4]\n",
    "\n",
    "    for doc in collection.aggregate(pipeline):\n",
    "        return float(doc['percentage_weekend'])\n",
    "\n",
    "get_percentage_sent_on_weekend(messages_collection)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)\n",
    "\n",
    "Write a function with parameter limit. The function should return for each email account: the number of emails sent, the number of emails received, and the total number of emails (sent and received). Use the following format: [{\"contact\": \"michael.simmons@enron.com\", \"from\": 42, \"to\": 92, \"total\": 134}] and the information contained in the To, From, and Cc headers. Sort the output in descending order by the total number of emails. Use the parameter limit to specify the number of results to be returned. If limit is null, the function should return all results. If limit is higher than null, the function should return the number of results specified as limit. limit cannot take negative values. [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_emails_between_contacts",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'contact': 'jeff.dasovich@enron.com',\n",
       "  'from': 67688,\n",
       "  'to': 12136,\n",
       "  'total': 79824},\n",
       " {'contact': 'rhonda.denton@enron.com',\n",
       "  'from': 32182,\n",
       "  'to': 73,\n",
       "  'total': 32255},\n",
       " {'contact': 'ginger.dernehl@enron.com',\n",
       "  'from': 29536,\n",
       "  'to': 1242,\n",
       "  'total': 30778},\n",
       " {'contact': 'jae.black@enron.com', 'from': 23018, 'to': 355, 'total': 23373},\n",
       " {'contact': 'sally.beck@enron.com',\n",
       "  'from': 15399,\n",
       "  'to': 6905,\n",
       "  'total': 22304}]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_emails_between_contacts(collection, limit):\n",
    "    \"\"\"\n",
    "    Shows the communications between contacts\n",
    "    Sort by the descending order of total emails using the To, From, and Cc headers.\n",
    "    :param `collection` A PyMongo collection object    \n",
    "    :param `limit` An integer specifying the amount to display, or\n",
    "    if null will display all outputs\n",
    "    :return A list of objects of the form:\n",
    "    [{\n",
    "        'contact': <<Another email address>>\n",
    "        'from': \n",
    "        'to': \n",
    "        'total': \n",
    "    },{.....}]\n",
    "    \"\"\"    \n",
    "    \n",
    "    from_data = []\n",
    "    to_data = []\n",
    "\n",
    "    from_emails = []\n",
    "    to_emails = []\n",
    "\n",
    "    common_emails = []\n",
    "\n",
    "    # limit stage to limit results (may be added to the pipeline for debugging)\n",
    "\n",
    "    limit_stage = {\n",
    "        '$limit': 100\n",
    "    }\n",
    "\n",
    "    final_list = []\n",
    "\n",
    "\n",
    "\n",
    "    # In the first stage we project the fields \"From\" and \"To\" for each email \n",
    "    # From: sender of the email (headers.From)\n",
    "    # To: receivers (To + Cc) of the email (headers.To + headers.Cc)\n",
    "\n",
    "    project_stage1 = {\n",
    "         '$project': {\n",
    "                         '_id': 0,\n",
    "                         'To': ['$headers.To', '$headers.Cc'],\n",
    "                         'From': '$headers.From',\n",
    "                     } \n",
    "    }\n",
    "\n",
    "    # Unwind stage: Deconstructs the field: 'To' to output a document for each element\n",
    "\n",
    "    unwind_stage1 = {\n",
    "        '$unwind': {'path': '$To'}\n",
    "    }\n",
    "\n",
    "    # After the unwind stage, there are docs of the form: {'To': None, 'From': 'michael.simmons@enron.com'}\n",
    "    # We filter out these docs with 'To': None\n",
    "\n",
    "    match_stage1 = {\n",
    "        '$match': {\n",
    "            'To': {'$ne': None}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # There are docs which have multiple ids in 'To field', separated by ', '. So we split them \n",
    "\n",
    "    project_stage2 = {\n",
    "        '$project': {\n",
    "                         'From': 1,\n",
    "                         'To': {'$split': ['$To', ', ']}\n",
    "\n",
    "                     } \n",
    "    }\n",
    "\n",
    "    # Another Unwind stage: Deconstructs the field: 'To' to output a document for each element\n",
    "\n",
    "    unwind_stage2 = {\n",
    "        '$unwind': {'path': '$To'}\n",
    "    }\n",
    "\n",
    "\n",
    "    # Now we have single ids in 'From' and 'To' fields \n",
    "\n",
    "    # But some ids in 'To' field are of the form: To': '\\r\\n\\tbryan.hull@enron.com'\n",
    "    # So we use $trim to get rid of these unwanted characters\n",
    "\n",
    "\n",
    "    project_stage3 = {\n",
    "        '$project': {\n",
    "            'To': {'$trim': {'input': '$To'}},\n",
    "            'From': 1\n",
    "\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Now we have documents of the form {'From': email_id1, 'To': email_id2} \n",
    "    # where each document represents an email between the 2 email ids\n",
    "\n",
    "    # Stage to group the accounts according to 'To' field and compute the count (the number of emails received)\n",
    "\n",
    "\n",
    "    group_stage1 = {\n",
    "        '$group': { \n",
    "            '_id': '$To',\n",
    "            'count_to': {'$sum': 1}          \n",
    "                  }\n",
    "    }\n",
    "\n",
    "    # Stage to group the accounts according to 'From' field and compute the count (the number of emails sent)\n",
    "\n",
    "\n",
    "    group_stage2 = {\n",
    "        '$group': { \n",
    "            '_id': '$From',\n",
    "            'count_from': {'$sum': 1}          \n",
    "                  }\n",
    "    }\n",
    "\n",
    "\n",
    "    # We create two pripelines with the above mentioned stages\n",
    "    # pipeline1: Compute docs for each email id and number of emails received by the id (count_to) \n",
    "    # pipeline2: Compute docs for each email id and number of emails sent by the id (count_from) \n",
    "\n",
    "\n",
    "    pipeline1 = [ project_stage1, unwind_stage1, match_stage1, project_stage2, \n",
    "                     unwind_stage2, project_stage3, group_stage1]\n",
    "\n",
    "    pipeline2 = [ project_stage1, unwind_stage1, match_stage1, project_stage2, \n",
    "                     unwind_stage2, project_stage3, group_stage2]\n",
    "\n",
    "\n",
    "    # Append the docs in two separate lists \n",
    "    for doc in collection.aggregate(pipeline1):\n",
    "        to_data.append(doc)\n",
    "\n",
    "    for doc in collection.aggregate(pipeline2):\n",
    "        from_data.append(doc)\n",
    "\n",
    "\n",
    "    # Create two lists that contains the email ids\n",
    "    for user_data in to_data:\n",
    "        email = user_data['_id']\n",
    "        to_emails.append(email)\n",
    "\n",
    "\n",
    "    for user_data in from_data:\n",
    "        email = user_data['_id']\n",
    "        from_emails.append(email)\n",
    "\n",
    "    # for each account in the 'to' data, add the entry to a final list \n",
    "\n",
    "    for user_data in to_data:\n",
    "        contact = user_data['_id']\n",
    "        to_value = user_data['count_to']\n",
    "        # total is set as to_value initially\n",
    "        dict_entry = {'contact': contact, 'to': to_value, 'from': 0, 'total': to_value}\n",
    "        final_list.append(dict_entry)\n",
    "\n",
    "    # now we check each account in the 'from' data\n",
    "    # if the account is already there in the 'to' email ids, then the entry must have been added in the previous step\n",
    "    # so simply modify values (set 'from' value and add it to the 'total' value)\n",
    "    # else create a new entry and append to the final list\n",
    "\n",
    "    for user_data in from_data:\n",
    "        contact = user_data['_id']\n",
    "        from_value = user_data['count_from']\n",
    "        if contact in to_emails:\n",
    "            # already entry created,just modify values\n",
    "            for user_data in final_list:\n",
    "                if user_data['contact'] == contact:\n",
    "                    # set 'From' field\n",
    "                    user_data['from'] = from_value\n",
    "                    # update 'Total' field\n",
    "                    user_data['total'] += from_value\n",
    "\n",
    "        else:\n",
    "            # new user data\n",
    "            dict_entry = {'contact': contact, 'to': 0, 'from': from_value, 'total': from_value}\n",
    "            final_list.append(dict_entry)\n",
    "\n",
    "    sorted_list = sorted(final_list, key=lambda k: k['total'], reverse=True) \n",
    "    \n",
    "    if limit is None:\n",
    "    \n",
    "        return sorted_list\n",
    "    else:\n",
    "        limit = int(limit)\n",
    "        return sorted_list[:limit]\n",
    "\n",
    "get_emails_between_contacts(messages_collection, 5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7)\n",
    "Write a function to find out the number of senders who were also direct receivers. Direct receiver means the email is sent to the person directly, not via cc or bcc. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_from_to_people(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the NUMBER of the people who have sent emails and received emails as direct receivers.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    #------------- FIND DIRECT RECEIVERS ---------------------------------\n",
    "\n",
    "    direct_receivers = []\n",
    "\n",
    "    direct_receivers1 = []\n",
    "\n",
    "    # find docs which have the headers.To field and the field is not empty and append the data to a list\n",
    "\n",
    "    for doc in collection.find({ 'headers.To': {'$exists': True, '$ne': ''} }):\n",
    "        direct_receivers.append(doc['headers']['To'])\n",
    "\n",
    "    # clean up the data and store the unique valyes in a new list\n",
    "\n",
    "    for receivers in direct_receivers:\n",
    "        for receiver in receivers.split(', '):\n",
    "            if receiver.strip(' \\t\\n\\r') not in direct_receivers1:\n",
    "                direct_receivers1.append(receiver.strip(' \\t\\n\\r'))\n",
    "                \n",
    "    # direct_receivers1 contains the unique list of direct reciver email ids\n",
    "    \n",
    "    #------------- FIND UNIQUE SENDERS ---------------------------------\n",
    "\n",
    "    senders = []\n",
    "\n",
    "    unique_senders = []\n",
    "\n",
    "    # find docs which have the headers.From field and the field is not empty and append the data to a list\n",
    "\n",
    "\n",
    "    for doc in collection.find({ 'headers.From': {'$exists': True, '$ne': ''} }):\n",
    "        senders.append(doc['headers']['From'].strip())\n",
    "\n",
    "    # store uniqie sender email ids in a list\n",
    "    for sender in senders:\n",
    "        if sender not in unique_senders:\n",
    "            unique_senders.append(sender)\n",
    "\n",
    "\n",
    "\n",
    "    #------------- FIND THE NUMBER OF COMMON ELEMENTS ---------------------------------\n",
    "\n",
    "    return len(set(direct_receivers1).intersection(senders1))\n",
    "\n",
    "get_from_to_people(messages_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8)\n",
    "Write a function with parameters start_date and end_date, which returns the number of email messages that have been sent between those specified dates, including start_date and end_date [4 points] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function can accept dates in the following formats (with or without timezone specified)\n",
    "\n",
    "- Tue, 14 Nov 2000 08:22:00 -0800 (PST)\n",
    "- Tue, 14 Nov 2000 08:22:00\n",
    "\n",
    "Whichever form is used, the function converts it into proper datetime format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_emails_between_dates(collection, start_date, end_date):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return All emails between the specified start_date and end_date\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE \n",
    "    \n",
    "    start_date_as_date = ''\n",
    "    end_date_as_date = ''\n",
    "    \n",
    "    # start date and end date to be in form: Tue, 14 Nov 2000 08:22:00 -0800 (PST)\n",
    "    # or in form: Tue, 14 Nov 2000 08:22:00\n",
    "    \n",
    "    start_date = start_date.strip()\n",
    "    end_date = end_date.strip()\n",
    "    \n",
    "    # check for format used and remove timezone if present\n",
    "    \n",
    "    \n",
    "    if start_date[25:].strip() == '-0800 (PST)':\n",
    "        start_date = start_date[:25].strip()\n",
    "        \n",
    "    if end_date[25:].strip() == '-0800 (PST)':\n",
    "        end_date = end_date[:25].strip()\n",
    "    \n",
    "    if len(start_date) <= 25 and len(end_date) <= 25:\n",
    "        # parse as datetime\n",
    "        start_date_as_date = datetime.strptime(start_date, '%a, %d %b %Y %H:%M:%S')\n",
    "        end_date_as_date = datetime.strptime(end_date, '%a, %d %b %Y %H:%M:%S')\n",
    "    \n",
    "    # limit stage to limit results (may be added to the pipeline for debugging)\n",
    "    \n",
    "    limit_stage = {\n",
    "    '$limit': 100\n",
    "    }\n",
    "\n",
    "\n",
    "    # This stage does the following operations:\n",
    "    # 1. $substr: Extracts the first 25 chars from the Date Field\n",
    "    # 2. $rtrim: removes trailing whitespace that appears if the day is a single digit number\n",
    "    # 3. $dateFromString: converts the string to a Date object\n",
    "    \n",
    "    project_stage = {\n",
    "         '$project': { 'DateOfMessage': \n",
    "                          {'$dateFromString': { 'dateString' : \n",
    "                                               { '$rtrim': {'input': {'$substr': ['$headers.Date', 0, 25] }}}\n",
    "\n",
    "                                              }\n",
    "                          }\n",
    "                     } \n",
    "    }\n",
    "    \n",
    "    # match stage to filter documents with Date >= start_date and Date <= end_date\n",
    "    \n",
    "    match_stage = {\n",
    "        '$match': {\n",
    "            '$and': [ {'DateOfMessage' : { '$gte': start_date_as_date } },  \n",
    "                      {'DateOfMessage' : { '$lte': end_date_as_date } } ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # group stage to count number of emails\n",
    "    \n",
    "    group_stage1 = {\n",
    "        '$group': {\n",
    "            '_id': None, 'count': {'$sum': 1}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    pipeline = [project_stage, match_stage, group_stage1]\n",
    "    \n",
    "    for doc in collection.aggregate(pipeline):\n",
    "        return int(doc['count'])\n",
    "    \n",
    "    \n",
    "get_emails_between_dates(messages_collection, \"Sat, 11 Nov 2000 16:37:00\", \"Tue, 14 Nov 2000 08:22:00 -0800 (PST)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "This task will assess your ability to use the Hadoop Streaming API and MapReduce to process data. For each of the questions below, you are expected to write two python scripts, one for the Map phase and one for the Reduce phase. You are also expected to provide the correct parameters to the `hadoop` command to run the MapReduce process. Write down your answers in the specified cells below.\n",
    "\n",
    "To get started, you need to download and unzip the YouTube dataset (available at http://edshare.soton.ac.uk/19547/) onto the machine where you have Hadoop installed (this should be the virtual machine provided).\n",
    "\n",
    "To help you, `%%writefile` has been added to the top of the cells, automatically writing them to \"mapper.py\" and \"reducer.py\" respectively when the cells are run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) \n",
    "Using Youtube01-Psy.csv, find the hourly interval in which most spam was sent. The output should be in the form of a single key-value pair, where the value is a datetime at the start of the hour with the highest number of spam comments. [9 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for mapper.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 3: hadoop: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Hadoop command to run the map reduce.\n",
    "\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "-files    \\\n",
    "-input    \\\n",
    "-mapper   \\\n",
    "-reducer  \\\n",
    "-output output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected key-value output format:\n",
    "#hour_with_most_spam\t\"2013-11-10T10:00:00\"\n",
    "\n",
    "#Additional key-value pairs are acceptable, as long as the hour_with_most_spam pair is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) \n",
    "Find all comments associated with a username (the AUTHOR field). Return a JSON array of all comments associated with that username. (This should use the data from all 5 data files: Psy, KatyPerry, LMFAO, Eminem, Shakira) [11 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 3: hadoop: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Hadoop command to run the map reduce.\n",
    "\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "-files    \\\n",
    "-input    \\\n",
    "-mapper   \\\n",
    "-reducer  \\\n",
    "-output output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected key-value output format:\n",
    "#John Smith\t[\"Comment 1\", \"Comment 2\", \"Comment 3\", \"etc.\"]\n",
    "#Jane Doe\t[\"Comment 1\", \"Comment 2\", \"Comment 3\", \"etc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
